---
layout: post
title: 机器学习系列14丨线性回归（二）
tag: 机器学习
---


### 一.线性回归api介绍

#### 1.通过正规方程优化

- sklearn.linear_model.LinearRegression(fit_intercept=True)

    - 通过正规方程优化
    - fit_intercept：是否计算偏置
    - LinearRegression.coef_：回归系数
    - LinearRegression.intercept_：偏置

代码演示：

    # 数据集
    from sklearn.datasets import load_boston
    # 数据集划分
    from sklearn.model_selection import train_test_split
    # 特征工程标准化
    from sklearn.preprocessing import StandardScaler
    # 线性回归-正规方程
    from sklearn.linear_model import LinearRegression
    # 模型评估
    from sklearn.metrics import mean_squared_error


    def linear_model1():
        """
        线性回归:正规方程
        :return:None
        """
        # 1.获取数据
        data = load_boston()

        # 2.数据集划分
        x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=22)

        # 3.特征工程-标准化
        transfer = StandardScaler()
        x_train = transfer.fit_transform(x_train)
        x_test = transfer.fit_transform(x_test)

        # 4.机器学习-线性回归(正规方程)
        estimator = LinearRegression()
        estimator.fit(x_train, y_train)

        # 5.模型评估
        # 5.1 预测值
        y_predict = estimator.predict(x_test)
        print("预测值为:\n", y_predict)
        print("模型中的系数为:\n", estimator.coef_)
        print("模型中的偏置为:\n", estimator.intercept_)

        # 准确率
        score = estimator.score(x_test, y_test)
        print("准确率是：\n", score)

        # 5.2 评价
        # 均方误差
        error = mean_squared_error(y_test, y_predict)
        print("均方误差是:\n", error)

    if __name__ == '__main__':
        linear_model1()

结果如下：

![20211015150712](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211015150712.png)

#### 2.通过梯度下降法优化

- sklearn.linear_model.SGDRegressor(loss="squared_loss", fit_intercept=True, learning_rate ='invscaling', eta0=0.01)
    - SGDRegressor类实现了随机梯度下降学习，它支持不同的loss函数和正则化惩罚项来拟合线性回归模型。
    - loss:损失类型
        - loss=”squared_loss”: 普通最小二乘法
    - fit_intercept：是否计算偏置
    - learning_rate : string, optional
        - 学习率填充
        - 'constant': eta = eta0
        - 'optimal': eta = 1.0 / (alpha * (t + t0)) [default]
        - 'invscaling': eta = eta0 / pow(t, power_t)
          - power_t=0.25:存在父类当中
        - 对于一个常数值的学习率来说，可以使用learning_rate=’constant’ ，并使用eta0来指定学习率。
    - SGDRegressor.coef_：回归系数
    - SGDRegressor.intercept_：偏置

代码演示：

    # 加载数据集
    from sklearn.datasets import load_boston
    # 数据集分割
    from sklearn.model_selection import train_test_split
    # 特征工程标准化,数据预处理
    from sklearn.preprocessing import StandardScaler
    # 线性回归-梯度下降法
    from sklearn.linear_model import SGDRegressor
    # 模型评估
    from sklearn.metrics import mean_squared_error


    def linear_model2():
        """
        线性回归:梯度下降法
        :return:None
        """
        # 1.获取数据
        data = load_boston()

        # 2.数据集划分
        x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=22)

        # 3.特征工程-标准化
        transfer = StandardScaler()
        x_train = transfer.fit_transform(x_train)
        x_test = transfer.fit_transform(x_test)

        # 4.机器学习-线性回归(梯度下降)
        # eta0 指定学习率
        estimator = SGDRegressor(max_iter=1000, learning_rate="constant", eta0=0.001)
        estimator.fit(x_train, y_train)

        # 5.模型评估
        # 5.1 预测值
        y_predict = estimator.predict(x_test)
        print("预测值为:\n", y_predict)
        print("模型中的系数为:\n", estimator.coef_)
        print("模型中的偏置为:\n", estimator.intercept_)

        # 准确率
        score = estimator.score(x_test, y_test)
        print("准确率是：\n", score)

        # 5.2 评价
        # 均方误差
        error = mean_squared_error(y_test, y_predict)
        print("均方误差是:\n", error)


    if __name__ == '__main__':
        linear_model2()


`learning_rate`一般进行动态的更新,也可以指定成为一个常数，但是不推荐，运行发现结果波动会比较大。

![20211015154724](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211015154724.png)

### 二.欠拟合、过拟合

#### 1.什么是欠拟合、过拟合

`过拟合`：一个假设 **在训练数据上能够获得比其他假设更好的拟合， 但是在测试数据集上却不能很好地拟合数据**，此时认为这个假设出现了过拟合的现象。(模型过于复杂)

`欠拟合`：一个假设在 **训练数据上不能获得更好的拟合，并且在测试数据集上也不能很好地拟合数据**，此时认为这个假设出现了欠拟合的现象。(模型过于简单)

#### 2.原因及解决办法

`欠拟合原因以及解决办法`

原因：学习到数据的特征过少

解决办法：

1）**添加其他特征项**，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。

2）**添加多项式特征**，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。

`过拟合原因以及解决办法`

原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点

解决办法：

1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。

2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。

3）正则化

4）减少特征维度，防止维灾难

#### 3.