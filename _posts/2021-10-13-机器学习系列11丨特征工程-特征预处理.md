---
layout: post
title: 机器学习系列11丨特征工程-特征预处理
tag: 机器学习
---


### 一.什么是特征预处理

#### 1.定义

通过一些转换函数将特征数据转换成更加合适算法模型的特征数据过程。

#### 2.为什么要进行归一化、标准化？

特征的单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，容易影响（支配）目标结果，是的一些算法无法学习到其他特征。

#### 3.包含的内容：

归一化和标准化

#### 4.特征预处理API

    sklearn.preprocessing

### 二.归一化

#### 1.定义

通过对原始数据进行变换把数据映射到（默认为[0，1]）之间

#### 2.公式

![20211013161315](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013161315.png)

作用于每一列，max为一列的最大值，min为一列的的最小值，那么x''为最终结果，mx,mi分别为指定区间值默认mx为1，mi为0

#### 3.API

`sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)...)`
`MinMaxScalar.fit_transform(X)`

演示代码如下：

    from sklearn.preprocessing import MinMaxScaler
    import pandas as pd

    data = pd.read_csv("./dating.txt")
    print(data)
    # 实例化一个转换器，取值转变为0~1
    transfer = MinMaxScaler(feature_range=(0, 1))
    # 调用fit_transform方法,转换成dataframe格式的数据
    minmax_data = transfer.fit_transform(data[['milage', 'Liters', 'Consumtime']])
    print("经过归一化处理之后的数据：", minmax_data)

查看运行结果，数据都变成0-1之间。

![20211013163917](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013163917.png)

#### 4.归一化总结

最大值与最小值非常容易受异常点影响，所以鲁棒性较差，归一化只适用于传统精确小数据场景。

### 三.标准化

#### 3.1 定义

通过对原始数据进行变换把数据变换到均值为0，标准差为1范围内

#### 3.2 公式

![20211013164852](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013164852.png)

作用与每一列，mean为平均值，分母为标准差

**对于归一化来说**：
如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变

**对于标准化来说**：
如果出现异常点，由于具有一定的数据量，少量的异常点对于平均值的影响并不大，从而方差改变很小。

#### 3.3 API

![20211013165359](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013165359.png)

#### 3.4 数据计算

    from sklearn.preprocessing import StandardScaler
    import pandas as pd

    data = pd.read_csv("./dating.txt")
    print(data)

    transfer = StandardScaler()
    minmax_data = transfer.fit_transform(data[['milage', 'Liters', 'Consumtime']])
    print("经过标准化处理之后的数据：", minmax_data)

结果如下：

![20211013165719](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013165719.png)

#### 3.5 总结

异常值影响小，适合现代复杂大数据场景

### 四.案例实现

#### 1.K-近邻算法API

![20211013170931](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211013170931.png)

**ball_tree和kd_tree区别**：kd_tree是一个超平面分割；ball_tree是一个超球体分割，一般用于维度大于20的场景。

#### 2.花种类的预测

Iris数据集是常用的分类实验数据集，是一类多重变量分析的数据集。

    """
    1.获取数据集
    2.数据基本处理
    3.特征工程
    4.模型训练
    5.模型评估
    """

    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.neighbors import KNeighborsClassifier

    # 1.获取数据集
    iris = load_iris()

    # 2.数据基本处理
    # 2.1 数据分割
    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22, test_size=0.2)

    # 3.特征工程
    # 3.1 实例化一个转换器
    transfer = StandardScaler()
    # 3.2 调用fit_transform方法
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.fit_transform(x_test)

    # 4.机器学习(模型训练)
    # 4.1 实例化一个估计器
    estimator = KNeighborsClassifier(n_neighbors=5)
    # 4.2 模型训练
    estimator.fit(x_train, y_train)

    # 5.模型评估
    # 5.1 输出预测值
    y_pre = estimator.predict(x_test)
    print("预测值是:\n", y_pre)
    print("预测值和真实值对比:\n", y_pre == y_test)

    # 5.2 输出准确率
    ret = estimator.score(x_test, y_test)
    print("准确率是:\n", ret)

