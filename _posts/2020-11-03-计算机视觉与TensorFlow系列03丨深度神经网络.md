---
layout: post
title: 计算机视觉与TensorFlow系列03丨深度神经网络
tag: 计算机视觉与TensorFlow
---

# 一.神经网络简介

## 1. 什么是神经网络

神经网络（NN）是一种模仿生物神经网络结构和功能的计算模型。

![20220106174056](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20220106174056.png)

特点：

- 同一层的神经元之间没连接
- 第N层的每个神经元和第N-1层的所有神经元相连（这就是full connected的含义），第N-1层神经元的输出就是第N层神经元的输入
- 每个连接都有一个权值

## 2. 神经元如何工作

人工神经元接收到一个或多个输入，对他们进行加权并相加，总和通过一个非线性函数产生输出。

![](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/202201071419613.png)

## 3. 激活函数

在神经元中引入了激活函数，它的本质是向神经网络中引入非线性因素的，通过激活函数，神经网络就可以拟合和各种曲线。如果不用激活函数，每一层的输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，引入非线性函数作为激活函数，那输出不再是输入的线性组合，可以逼近任意函数。常用的激活函数有：

### 3.1  Sigmoid/Logistics函数

![](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/202201071636247.png)

代码实现：

```python
# 导入相应的工具包
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

# 定义x的取值范围
x = np.linspace(-15, 15, 100)
# 直接使用tf实现
y = tf.nn.sigmoid(x)
# 绘图
plt.plot(x, y)
plt.grid()
plt.show()运行结果：
```

![](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/202201071642930.png)

### 3.2 tanh(双曲正切曲线)

![](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/202201071714711.png)

tanh也是一种非常常见的激活函数。与sigmoid相比，它是以0为中心的，使得其收敛速度要比sigmoid快，减少迭代次数。然而，从图中可以看出，tanh两侧的导数也为0，同样会造成梯度消失。

若使用时可在隐藏层使用tanh函数，在输出层使用sigmoid函数。

代码实现：

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

# 定义x的取值范围
x = np.linspace(-15, 15, 100)
# 直接使用tensorflow实现
y = tf.nn.tanh(x)
# 绘图
plt.plot(x, y)
# 添加网格
plt.grid()
plt.show()
```

运行结果:

![](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/202201071727472.png)

### 3.3  RELU







