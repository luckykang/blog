---
layout: post
title: 机器学习系列15丨逻辑回归
tag: 机器学习
---

### 一.逻辑回归介绍

#### 1.逻辑回归是什么

逻辑回归（Logistic Regression）是机器学习中的一种分类模型，逻辑回归是一种**分类算法**，虽然名字中带有回归，但是它与回归之间有一定的联系。由于算法的简单和高效，在实际中应用非常广泛。

#### 2.逻辑回归应用场景

**是解决二分类问题的利器**，具体场景如下：

- 广告点击率
- 是否为垃圾邮件
- 是否患病
- 金融诈骗
- 虚假账号

#### 3.逻辑回归的原理

#####  3.1 输入

逻辑回归的输入就是线性回归的输出。

![20211018160747](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018160747.png)

##### 3.2 激活函数

把整体的值映射到[0,1]，再设置一个阈值，进行分类判断。

![20211018163813](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018163813.png)

输出结果解释：假设有两个类别A，B，并且假设我们的概率值为属于A(1)这个类别的概率值。现在有一个样本的输入到逻辑回归输出结果0.6，那么这个概率值超过0.5，意味着我们训练或者预测的结果就是A(1)类别。那么反之，如果得出结果为0.3那么，训练或者预测结果就为B(0)类别。

![20211018163913](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018163913.png)

##### 3.3 损失

逻辑回归的损失，称之为 **对数似然损失**。借助了log思想，进行完成。真实值等于0，1  两种情况进行划分。

分开类别公式：

![20211018165146](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018165146.png)

综合完整损失函数公式：

![20211018164111](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018164111.png)

log(P), P值越大，结果越小，所以我们可以对着这个损失的式子去分析

![20211018164211](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211018164211.png)

##### 3.4 优化

同样使用梯度下降优化算法，去减少损失函数的值。这样去更新逻辑回归前面对应算法的权重参数，**提升原本属于`1`类别的概率，降低原本属于`0`类别的概率。**

### 二.API介绍与代码演示

#### 1.api介绍

sklearn.linear_model.LogisticRegression(solver='liblinear', penalty=‘l2’, C = 1.0)

- solver可选参数:{'liblinear', 'sag', 'saga','newton-cg', 'lbfgs'}，

    - 默认: 'liblinear'；用于优化问题的算法。
    - 对于小数据集来说，“liblinear”是个不错的选择，而“sag”和'saga'对于大型数据集会更快。

    - 对于多类问题，只有'newton-cg'， 'sag'， 'saga'和   'lbfgs'可以处理多项损失;“liblinear”仅限于“one-versus-rest”分类。

- penalty：正则化的种类

- C：正则化力度

**默认将类别数量少的当做正例**

LogisticRegression方法相当于 SGDClassifier(loss="log", penalty=" "),SGDClassifier实现了一个普通的随机梯度下降学习。而使用LogisticRegression(实现了SAG)

#### 2.代码演示

    import pandas as pd
    import numpy as np
    # 分割数据
    from sklearn.model_selection import train_test_split
    # 特征预处理
    from sklearn.preprocessing import StandardScaler
    # 逻辑回归
    from sklearn.linear_model import LogisticRegression

    import ssl
    ssl._create_default_https_context = ssl._create_unverified_context

    # 1.获取数据
    # 癌症分类预测-良／恶性乳腺癌肿瘤预测
    # https://archive.ics.uci.edu/ml/machine-learning-databases/

    names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',
            'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',
            'Normal Nucleoli', 'Mitoses', 'Class']

    # data = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data")
    data = pd.read_csv("./breast-cancer-wisconsin.data", names=names)

    # 2.数据处理
    # 2.1缺失值处理
    data = data.replace(to_replace="?", value=np.nan)
    data = data.dropna()
    data.describe()

    # 2.2确定特征值，目标值
    x = data.iloc[:, 1:-1]
    x.head()
    y = data["Class"]
    y.head()
    # 2.3分割数据
    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=2, test_size=0.2)
    # 3.特征工程（标准化）
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.fit_transform(x_test)

    # 4.机器学习-逻辑回归
    estimator = LogisticRegression()
    estimator.fit(x_train, y_train)

    # 5.模型评估
    y_pre = estimator.predict(x_test)
    print("预测值是：", y_pre)
    score = estimator.score(x_test, y_test)
    print("准确率是", score)

运行结果：

![20211019145623](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019145623.png)

### 三.分类评估方法

#### 1.混淆矩阵

在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)

![20211019153345](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019153345.png)

#### 2.精确率(Precision)与召回率(Recall)

**精确率**：预测结果为正例样本中真实为正例的比例（查的准不准）

`TP / (TP+FP)`

![20211019153525](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019153525.png)

**召回率：** 真实为正例的样本中预测结果为正例的比例（查的全不全）

`TP / (TP+FN)`

![20211019153714](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019153714.png)

#### 3.F1-score

F1-score，反映了模型的稳健型

![20211019153955](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019153955.png)

#### 4.分类评估报告API

sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None)

 - y_true：真实目标值
 - y_pred：估计器预测目标值
 - labels:指定类别对应的数字
 - target_names：目标类别名称
 - return：每个类别精确率与召回率

#### 5.分类评估报告API的代码演示

    # 分类评估报告
    from sklearn.metrics import classification_report

    # 5.2 其他评估
    ret = classification_report(y_test, y_pre)
    print(ret)

结果如下：

![20211019160907](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019160907.png)

添加labels和target_names参数

    ret = classification_report(y_test, y_pre, labels=(2, 4), target_names=("良性", "恶性"))

结果如下：

![20211019161957](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019161957.png)

#### 6.ROC曲线和AUC指标

TPR = TP / (TP + FN)

所有真实类别为1的样本中，预测类别为1的比例

FPR = FP / (FP + TN)

所有真实类别为0的样本中，预测类别为1的比例

**ROC曲线** 

ROC曲线的横轴就是FPRate(FPR)，纵轴就是TPRate(TPR)，图像绘制形成一个指标AUC。当二者相等时，**表示的意义则是：** 对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的，此时AUC为0.5

![20211019165130](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019165130.png)

**AUC的概率意义**是随机取一对正负样本，正样本得分大于负样本的概率

AUC的最小值为0.5，最大值为1，取值越高越好

AUC=1，完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。

0.5<AUC<1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

***最终AUC的范围在[0.5, 1]之间，并且越接近1越好***

#### 7.AUC计算API介绍与使用

**API介绍**

from sklearn.metrics import roc_auc_score
 - sklearn.metrics.roc_auc_score(y_true, y_score)
    - 计算ROC曲线面积，即AUC值
    - y_true：每个样本的真实类别，必须为0(反例),1(正例)标记
    - y_score：预测得分，可以是正类的估计概率、置信值或者分类器方法的返回值

**API使用**

    # 不平衡二分类问题评估方法-AUC
    # 如果y_test>3,赋值为1，否则为0
    y_test = np.where(y_test > 3, 1, 0)
    # y_true 要把正例转换为1，反例转换为0
    print("AUC指标", roc_auc_score(y_true=y_test, y_score=y_pre))

结果：

![20211019170925](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211019170925.png)

#### 总结

AUC只能用来评价二分类

AUC非常适合评价样本不平衡中的分类器性能

