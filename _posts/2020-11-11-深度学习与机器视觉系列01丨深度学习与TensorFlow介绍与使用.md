---
layout: post
title: 深度学习与机器视觉系列01丨深度学习与TensorFlow介绍与使用
tag: 深度学习与机器视觉
---

## 一.深度学习介绍

![20211111104731](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211111104731.png)


### 1.深度学习与机器学习的区别

#### （1）特征提取方面

- 机器学习

机器学习的特征工程要靠手动完成，而且需要大量领域专业知识

- 深度学习

通常由多个层组成，它们通常将更简单的模型组合在一起，通过将数据从一层传递到另一层来构建更复杂的模型。通过大量数据的训练自动得到模型，不需要人工设计特征提取环节

#### （2）数据量

- 机器学习

参数较少，执行时间短

- 深度学习

参数庞大，执行时间长，需要通过大量数据的多次优化来训练参数

第一、它们需要大量的训练数据集

第二、是训练深度神经网络需要大量的算力

可能要花费数天、甚至数周的时间，才能使用数百万张图像的数据集训练出一个深度网络。所以

> 需要强大的GPU服务器来进行计算

> 全面管理的分布式训练与预测服务——比如谷歌 TensorFlow 云机器学习平台,可能会解决这些问题

### 2.各自的算法代表

- 机器学习

朴素贝叶斯、决策树

- 深度学习

神经网络

### 3.应用场景

- 图像识别领域：包括物体识别、场景识别、车型识别、人脸检测跟踪、人脸关键点定位、人脸身份认证等

- 自然语言处理：机器翻译、文本识别、聊天对话等

- 语音技术:语音识别

## 二.TensorFlow介绍

### 1.TensorFlow的特点

- 语言多样

C++实现，用python封装的，支持多语言接口

- 使用分发策略进行分发训练
  
对于大型ML训练任务，分发策略API使得在不更改模型定义的情况下，可以轻松的在不同的硬件配置上分发和训练模型。支持一系列硬件加速器，如CPU、GPU和TPU。

- Tensorboard可视化

Tensorboard是TensorFlow的一组Web应用，用来监控TensorFlow运行过程

- 在任何平台上的生产中进行强大的模型部署

训练完成并保存了模型，就可以直接在应用程序中执行，或者使用部署库为其提供服务：

> TensorFlow服务: 允许模型通过HTTP/REST或GRPC/协议缓冲区提供服务的TensorFlow库构建。

> TensorFlow Lite: TensorFlow针对移动端和嵌入式设备的轻量级解决方案，提供了在Android、ios和嵌入式系统上部署模型的能力。

> Tensorflow.js: 支持在JavaScript环境中部署模型，例如在web浏览器或服务端通过Node.js部署模型。还支持在JavaScript中定义模型，并使用类似于Kera的API直接在web浏览器中进行训练。

### 2.TensorFlow使用技巧

- 使用`tf.keras`构建、训练和验证模型，tf相关API用于损失计算修改等。

- tensorflow提供模型训练、模型部署

## 三.TensorFlow结构

### 1. 实现一个加法来理解

    import tensorflow as tf

    # 实现加法
    a = tf.constant(11.0)
    b = tf.constant(20.0)
    c = tf.add(a, b)
    print(c)

    # 开启会话，才会运行
    with tf.compat.v1.Session() as sess:
        sum_tf = sess.run(c)
        print("在sess中的值为：", sum_tf)

运行结果：

![20211112173953](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211112173953.png)

**如果遇到报错：**

`I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2`

意思是 CPU 支持AVX2 FMA（加速CPU计算），但安装的 TensorFlow 版本不支持

**解决办法：**

（1）如果没有太大计算速度的需求，可以加两行代码忽略

    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

（2）如果有需要优化CPU，可以重新编译tensorflow源码以兼容AVX。

可参考link: [https://github.com/lakshayg/tensorflow-build](https://github.com/lakshayg/tensorflow-build)

### 2.Tensorflow的工作流程

- 根据需求，创建计算图Graph
- 开启会话Session，读取数据运行Graph
- 获取结果

TensorFlow 程序通常被组织成**一个构建图阶段**和**一个执行图阶段**。

在构建阶段，数据与操作的执行步骤被描述成一个图。

在执行阶段，使用会话执行构建好的图中的操作。

- 图和会话 ：
    - 图（graph）：这是 TensorFlow 将计算表示为指令之间的依赖关系的一种表示法
    - 会话（session）：TensorFlow 跨一个或多个本地或远程设备运行数据流图的机制
- 张量（tensor）：TensorFlow 中的基本数据对象
- 节点（operation）：提供图当中执行的操作

### 3.数据流图介绍

![20211112180618](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211112180618.png)

TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源框架。

节点（Operation）在图中表示数学操作，线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。

## 四.图与TensorBoard

### 1.什么是图结构

图包含了一组tf.Operation代表的计算单元对象和tf.Tensor代表的计算单元之间流动的数据。

### 2.图相关操作

> 默认图

通常TensorFlow会默认帮我们创建一张图。查看默认图的两种方法：

- 通过调用 **tf.compat.v1.get_default_graph()** 访问 ，要将操作添加到默认图形中，直接创建OP即可。

- op、sess都含有graph属性 ，默认都在一张图中

演示：

    import tensorflow as tf
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

    def graph_demo():
        # 图的演示
        a_t = tf.constant(10)
        b_t = tf.constant(20)
        # 不提倡直接运用这种符号运算符进行计算
        # 更常用tensorflow提供的函数进行计算
        # c_t = a_t + b_t
        c_t = tf.add(a_t, b_t)
        print("tensorflow实现加法运算：\n", c_t)

        # 获取默认图
        default_g = tf.compat.v1.get_default_graph()
        print("获取默认图：\n", default_g)

        # 数据的图属性
        # print("a_t的graph:\n", a_t.graph)
        # print("b_t的graph:\n", b_t.graph)
        # # 操作的图属性
        # print("c_t的graph:\n", c_t.graph)

        # 开启会话
        with tf.compat.v1.Session() as sess:
            sum_t = sess.run(c_t)
            print("在sess当中的sum_t:\n", sum_t)
            # 会话的图属性
            print("会话的图属性：\n", sess.graph)

    if __name__ == '__main__':
        graph_demo()

> 创建图

可以通过 **tf.Graph()** 自定义创建图。如果要在这张图中创建OP，典型用法是使用 **tf.Graph.as_default()** 上下文管理器

    import tensorflow as tf
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

    def graph_demo():
        # 创建图
        new_g = tf.Graph()
        with new_g.as_default():
            new_a = tf.constant(13.0)
            new_b = tf.constant(14.0)
            new_c = tf.add(new_a, new_b)
        # 会话只运行默认图，创建的图需要参数指定
        with tf.compat.v1.Session(graph=new_g) as sess:
            sum_t = sess.run(new_c)
            print("在sess当中的sum_t:\n", sum_t)

    if __name__ == '__main__':
        graph_demo()

### 3.Tensorboard

TensorFlow有一个亮点就是，我们能看到自己写的程序的可视化效果，这个功能就是Tensorboard。它是一个可视化工具。通过它，我们可以更方便地对 TensorFlow 程序的理解、调试与优化。

**那么如何实现程序可视化的?**

> 第一步：数据序列化-events文件

TensorBoard 通过读取 TensorFlow 的事件文件来运行，需要将数据生成一个序列化的 ***Summary protobuf*** 对象。

    # 返回filewriter,写入事件文件到指定目录(最好用绝对路径)，以提供给tensorboard使用
    tf.summary.FileWriter('./tmp/summary/', graph=sess.graph)

这将在指定目录中生成一个 **event** 文件，其名称格式如下：

    events.out.tfevents.{timestamp}.{hostname}

> 第二步：启动Tensorboard

    tensorboard  --logdir="./tmp/tensorflow/summary/"

在浏览器中打开 TensorBoard 的图页面 `127.0.0.1:6006` ，会看到与以下图形类似的图,在GRAPHS模块我们可以看到以下图结构

代码演示：

    import tensorflow as tf
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

    def graph_demo():
        # 创建图
        new_g = tf.Graph()
        with new_g.as_default():
            new_a = tf.constant(13.0)
            new_b = tf.constant(14.0)
            new_c = tf.add(new_a, new_b)
        # 开启会话,参数要指向创建的图，如果不指定则指定默认图
        with tf.compat.v1.Session(graph=new_g) as sess:
            sum_t = sess.run(new_c)
            print("在sess当中的sum_t:\n", sum_t)
            # 写入到events文件中
            filewriter = tf.compat.v1.summary.FileWriter("./tmp/summary/", graph=sess.graph)
    if __name__ == '__main__':
        graph_demo()

生成event文件：

![20211126171600](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126171600.png)

在当前项目路径的的虚拟环境中，输入下面命令

![20211126172211](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126172211.png)

即会启动一个6006端口的本地服务，我们可以查看程序的详情

![20211126172152](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126172152.png)

### 4.OP

一个操作对象(Operation)是TensorFlow图中的一个节点, 可以接收0个或者多个Tensor, 并且可以输出0个或者多个Tensor，Operation对象是通过OP构造函数如`tf.matmul()`创建的。

常见的OP有哪些：

![20211126173127](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126173127.png)

怎么理解OP呢？

![20211126175213](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126175213.png)

"<OP_NAME>" 是生成该张量的指令的名称，name参数对其进行修改。

"i" 是一个整数，它表示该张量在指令的输出中的索引,一般为0

![20211126183928](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211126183928.png)

