---
layout: post
title: NLP与Pytorch01丨深度学习和神经网络的介绍
tag: NLP
---

## 一. 深度学习的介绍

### 1. 深度学习的概念

深度学习（deep learning）是机器学习的分支，是一种以**人工神经网络**为架构，对数据进行特征学习的算法。

### 2. 深度学习与机器学习区别

#### 2.1 从特征提取角度

机器学习需要有人工的特征提取的过程

深度学习特征提取的过程可以通过深度神经网络自动完成

![20211215143039](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215143039.png)

#### 2.2 从数据量角度

深度学习需要大量的训练数据集，会有更高的效果

深度学习训练深度神经网络需要大量的算力，因为其中有更多的参数

### 3. 深度学习的应用场景

#### 3.1 图像识别

物体识别

场景识别

人脸检测跟踪

人脸身份验证

#### 3.2 自然语言处理

机器翻译

文本识别

聊天对话

#### 3.3 语音技术

语音识别

### 4.常见的深度学习框架

常见的有Tensorflow、Caffe2、Theano、Pytorch、Mxnet。

Pytorch的使用和python的语法相同，整个操作类似Numpy的操作，并且Pytorch使用的是动态计算，会让代码的调试变得更加简单。

## 二. 神经网络的介绍

### 1. 人工神经网络的概念

人工神经网络，简称神经网络（Neural Network），是一种模仿生物神经网络的结构和功能的数学模型，**用于对函数进行估计或近似**。

### 2.神经元概念

一个简单的神经元如下图：

![20211215145755](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215145755.png)

一个神经元的功能是求得输入向量与权向量的内积后，经一个非线性传递函数得到一个标量结果。

### 3.单层神经网络

是最基本的神经元网络形式，由有限个神经元构成，所有神经元的输入向量都是同一个向量。由于每个神经元都会产生一个标量结果，所以单层神经元的输出是一个向量，向量的维数等于神经元的数目。

![20211215151706](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215151706.png)

### 4.感知机

感知机由**两层神经网络**组成，**输入层**接收外界输入信号后传递给**输出层（输出+1正例，-1反例）**,输出层是M-P神经元。其中w0,w1...都表示权重。

是一个简单的二分类模型，给定阈值，判断数据属于哪一部分。

![20211215152027](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215152027.png)

**感知机的作用：**

把一个n维向量空间用一个超平面分割成两部分，给定一个输入向量，超平面可以判断出这个向量位于超平面的哪一边，得到输入时正类或者反类。如果是2维空间就是一条直线把一个平面分为两个部分。

### 5.多层神经网络

是由单层神经网络进行叠加之后得到的，所以形成了层的概念。常见的多层神经网络有如下结构：

- 输入层（input layer）：众多神经元接收大量输入消息。输入的消息称为**输入向量**。

- 输出层（output layer）： 消息在神经元链接中传输、分析、权衡，形成输出结果。输出的消息称为**输出向量**。

- 隐藏层（Hidden layer）：简称`隐层`，是输入层和输出层之间众多神经元和链接组成的各个层面。**隐层可以有一层或多层。隐层的节点（神经元）数目不定**，但数目越多神经网络的非线性越显著，从而神经网络的强健性更显著。

![20211215160436](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215160436.png)

- 全链接层

第N层和第N-1层中每个神经元相互链接，我们称这一层为全连接层。全链接层进行的是 y = Wx + b 

![20211215170009](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211215170009.png)

### 6.激活函数

#### 6.1什么是线性函数

什么是系统:可以理解为函数，f，模型

f(x1 + x2) = y1 + y2

f(kx1) = ky1 

满足上述两个条件的的即为线性函数。

#### 6.2非线性激活函数

如果我们在感知机的基础上加上**非线性的激活函数**之后，输出的结果就不再是一条直线。

![20211216104355](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211216104355.png)

如上图，右边是sigmoid函数，对感知机的结果，通过sigmoid函数进行处理。

#### 6.3激活函数作用

- 增加模型的非线性分割能力
- 提高模型鲁棒性（稳健性）
- 缓解梯度消失问题
- 加速模型收敛等

#### 6.4常见的激活函数有：

![20211216102826](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211216102826.png)

由图可知：

`sigmoid`只会输出整数，靠近0的输出变化率最大

`tanh`和sigmoid不同的是，`tanh`输出可以是负数

`Relu`是输入只能大于0，如果你输入含有负数，`Relu`就不合适。如果输入是图片格式，`Relu`就挺常用的，因为图片的像素值作为输入时取值为[0，255]。



