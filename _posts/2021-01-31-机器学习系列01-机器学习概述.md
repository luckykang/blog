---
layout: post
title: 机器学习系列01-机器学习概述
tag: 机器学习
---

### 1. 主要分支

- 计算机视觉(CV)

计算机视觉是指机器感知环境的能力。物体检测和人脸识别是其比较成功的研究领域。

- 语音识别

语音识别是指识别语音，并将其转换成对应文本的技术。语音识别目前仍然面临着`声纹识别`和`鸡尾酒会效应`等一些难题。现代语音识别系统严重依赖云，在离线时可能无法取得理想的效果。

- 文本发掘/分类

- 机器翻译

利用机器的力量将一种自然语言(源语言)的文本翻译成另一种语言(目标语言)。

- 机器人

分为两类：固定机器人和移动机器人。


### 2. 工作流程

机器学习：是从数据中自动分析获得模型，并利用模型对未知数据进行预测。

#### 2.1 机器学习工作流程总结：

* 1.获取数据
* 2.数据基本处理
* 3.特征工程
* 4.机器学习(模型训练)
* 5.模型评估
 
    * 结果达到要求，上线服务
    * 没有达到要求，重新上面步骤

![20210623164914](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623164914.png)

在数据集中一般：
* 一行数据我们称为一个样本
* 一列数据我们称为一个特征
* 有些数据有目标值(标签值)，比如下图电影类型就是目标值

![20210623170653](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623170653.png)

数据分割：

* 机器学习一般的数据集划分为两个部分：
    * 训练数据：用于训练，构建模型
    * 测试数据：在模型检验时使用，用于评估模型是否有效

#### 2.2 数据基本处理

对数据进行缺失值、去除异常值等处理

#### 2.3 特征工程

特征工程指的是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好作用的过程。

* 会直接影响机器学习的效果

为什么需要特征工程？

数据和特征决定了机器学习的上限，而模型和算法只是逼近了这个上限而已。

特征工程包含内容：

* 特征提取：将任意数据(如文本或图像)转换为可用于机器学习的数字特征。

* 特征预处理：通过一些转换函数将特征数据转换为更合适算法模型的特征数据过程

![20210623172819](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623172819.png)

* 特征降维：指在某些限定条件下，降低随机变量(特征)个数，得到一组`不相关`主变量的过程

### 3. 机器学习算法分类

#### 3.1 根据数据集组成不同，分为：

* 监督学习
* 无监督学习
* 半监督学习
* 强化学习

#### 3.2 监督学习

定义：输入数据是由输入特征值和目标值所组成。

* 函数的输出可以是一个连续的值(称为回归)
* 或是输出是有限个离散值(称为分类)

#### 3.3 无监督学习

定义：输入数据是由输入特征组成，没有目标值

* 输入特征没有被标记，也没有确定的结果，样本数据类别未知；
* 需要根据样本间的相似性对样本集进行类别划分。

![20210623175338](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623175338.png)

#### 3.4 半监督学习

定义：训练集同时包含有标记样本数据和未标记样本数据。

##### 监督学习和半监督学习区别：

监督学习训练方式：大量未被标记的(没有目标值)数据，让专家进行标记，得到标记过的数据，然后训练得到模型。

半监督学习训练方式：
大量未被标记的数据，取少部分数据让专家进行标记，通过少量的数据训练出一个初步的模型，初步的模型除了用少量的标记过的数据，还有大量没有标记过的数据来进行整体的模型得出。

#### 3.5 强化学习

定义：自动进行决策，并且可以做连续决策。

强化学习的目标是获得最多的累计奖励。

##### 下图为监督学习和强化学习的区别：

![20210623181519](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623181519.png)

什么是独立同分布？

`独立`是说每次抽样之间没关系，不会互相影响

`同分布`是说每次抽样，样本服从同一个分布

`独立同分布`是说每次抽样之间独立而且同分布

西瓜书解释：输入空间中的所有样本服从一个隐含未知的分布，训练数据所有样本都是独立地从这个分布上采样而得。


##### 对比小结：

![20210623183030](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623183030.png)

### 4. 模型评估

按照数据集的目标值不同，可以把模型评估分为`分类模型评估`和`回归模型评估`。

#### 4.1 分类模型评估

* 准确率

    * 预测正确的数占样本总数的比例

* 其他评价指标：精确率、召回率、F1-score、AUC指标等

#### 4.2 回归模型评估

均方根误差（RMSE）

* RMSE是一个衡量回归模型误差率的常用公式。不过，它仅能比较误差是相同单位的模型。如下图，p是预测值，a是真实值。

![20210623184239](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20210623184239.png)

* 其他评价指标：相对平方误差(RSE)、平均绝对误差(MAE)、相对绝对误差(RAE)

#### 4.3 拟合

模型评估用于评价训练好的模型的表现效果，其表现效果大致可以分为两类：过拟合、欠拟合。

在训练过程中，可能遇到下面问题：

训练数据训练的很好，误差不大，为什么测试集上有问题呢？

当算法在某个数据集当中出现这种情况，可能就出现了拟合问题。

##### 4.3.1 欠拟合

模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。

##### 4.3.2 过拟合

模型在训练样本中表现过于优越，导致在测试数据集表现不佳。


