---
layout: post
title: 机器学习系列20丨聚类算法
tag: 机器学习
---

### 一.聚类算法简介

#### 1.概念

一种典型的**无监督学习算法**，主要用于将相似的样本自动归到一个类别中。

在聚类算法中根据样本之间的相似性，将样本划分到不同的类别中，对于不同的相似度计算方法，会得到不同的聚类结果，常用的相似度计算方法有欧式距离法。

使用不同的聚类准则，产生的聚类结果不同。

#### 2.应用

- 用户画像，广告推荐，Data Segmentation，搜索引擎的流量推荐，恶意流量识别

- 基于位置信息的商业推送，新闻聚类，筛选排序

- 图像分割，降维，识别；离群点检测；信用卡异常消费；发掘相同功能的基因片段

#### 3.聚类算法与分类算法最大的区别

聚类算法是**无监督**的学习算法，而分类算法属于**监督**的学习算法。

### 二.聚类算法API的使用

#### 1.api介绍

- sklearn.cluster.KMeans(n_clusters=8)

    - 参数:
        - n_clusters:开始的聚类中心数量
        - 整型，缺省值=8，生成的聚类数，即产生的质心（centroids）数。
    - 方法:
        - estimator.fit(x)
        - estimator.predict(x)
        - estimator.fit_predict(x)
        - 计算聚类中心并预测每个样本属于哪个类别,相当于先调用fit(x),然后再调用predict(x)

#### 2.使用

    import matplotlib.pyplot as plt
    from sklearn.datasets.samples_generator import make_blobs
    # 使用k-means进行聚类
    from sklearn.cluster import KMeans
    # CH方法评估
    from sklearn.metrics import calinski_harabaz_score

    # 获取数据
    # X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，
    # 有多少样本 n_samples
    # 有几个特征 n_features
    # 簇中心在[-1,-1], [0,0],[1,1], [2,2]
    # 簇方差分别为[0.4, 0.2, 0.2, 0.2]
    # 随机数种子 random_state
    X, Y = make_blobs(n_samples=1000, n_features=2, centers=[[-1, -1], [0, 0], [1, 1], [2, 2]],
                    cluster_std=[0.4, 0.2, 0.2, 0.2],
                    random_state=9)

    # 模型训练
    # n_clusters表示聚类中心数量
    estimator = KMeans(n_clusters=5, random_state=2)
    y_pre = estimator.fit_predict(X)

    # 模型可视化
    plt.scatter(X[:, 0], X[:, 1], c=y_pre)
    plt.show()

    # CH方法评估聚类分数
    print(calinski_harabaz_score(X, y_pre))

结果:

![20211028175647](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/20211028175647.png)

